# Google GenAI MCP Toolbox Configuration - MINIMAL LOAD FOR DECIDER AGENT
# This file defines only the essential database sources and tools used by the decider agent
# Optimized for performance by loading only required tools

# Database sources
sources:
  cloudsql:
    kind: cloud-sql-postgres
    project: celtic-origin-472009-n5
    region: us-central1
    instance: testgen-db
    database: testgen_db
    user: testgen_user
    password: testgen_pass

  memorystore-redis:
    kind: redis
    address:
      - 10.202.18.147:6379

# Essential tools for HITL Enhanced Decider Agent
tools:
  # HITL Store Original Requirements (alias: store-original-requirements)
  hitl-store-original-requirements:
    kind: postgres-sql
    source: cloudsql
    description: Store original requirements analysis and update session to requirements_analyzed
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: analysis_response
        type: string
        description: Original analysis response from requirement_analyzer agent
    statement: |
      WITH req_insert AS (
        INSERT INTO requirements (id, session_id, original_content, requirement_type, status)
        VALUES ($1::text || '_req_original_' || substring(gen_random_uuid()::text, 1, 8), $1::text, $2::text, 'original_analysis', 'active')
        ON CONFLICT (id) DO NOTHING
        RETURNING id, session_id, original_content, requirement_type, created_at
      ),
      session_update AS (
        UPDATE sessions
        SET status = 'requirements_analyzed', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        json_build_object(
          'database_result', json_build_object(
            'id', r.id,
            'session_id', r.session_id,
            'original_content', r.original_content,
            'requirement_type', r.requirement_type,
            'created_at', r.created_at,
            'session_status', s.status,
            'session_updated_at', s.updated_at
          ),
          'cache_data', json_build_object(
            'session_id', r.session_id,
            'requirements', json_build_array(
              json_build_object(
                'id', r.id,
                'content', r.original_content,
                'type', r.requirement_type,
                'status', 'active',
                'created_at', r.created_at
              )
            ),
            'status', s.status,
            'updated_at', s.updated_at
          ),
          'next_action', 'CALL cache-requirements-data with session_id and cache_data'
        ) as result
      FROM req_insert r, session_update s;

  # Alias for hitl-store-original-requirements
  store-original-requirements:
    kind: postgres-sql
    source: cloudsql
    description: Store original requirements analysis and update session to requirements_analyzed (alias)
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: analysis_response
        type: string
        description: Original analysis response from requirement_analyzer agent
    statement: |
      WITH req_insert AS (
        INSERT INTO requirements (id, session_id, original_content, requirement_type, status)
        VALUES ($1::text || '_req_original_' || substring(gen_random_uuid()::text, 1, 8), $1::text, $2::text, 'original_analysis', 'active')
        ON CONFLICT (id) DO NOTHING
        RETURNING id, session_id, original_content, requirement_type, created_at
      ),
      session_update AS (
        UPDATE sessions
        SET status = 'requirements_analyzed', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        r.id, r.session_id, r.original_content, r.requirement_type, r.created_at,
        s.status as session_status, s.updated_at as session_updated_at
      FROM req_insert r, session_update s;

  # HITL Refine Analysis Workflow
  hitl-refine-analysis-workflow:
    kind: postgres-sql
    source: cloudsql
    description: HITL Refine workflow - store refined analysis with human feedback
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: refined_analysis
        type: string
        description: Refined analysis incorporating human feedback
      - name: human_feedback
        type: string
        description: Human feedback that triggered refinement
      - name: iteration_count
        type: integer
        description: Current iteration number
    statement: |
      WITH req_insert AS (
        INSERT INTO requirements (id, session_id, original_content, edited_content, requirement_type, status, version)
        VALUES (
          $1::text || '_req_refined_' || substring(gen_random_uuid()::text, 1, 8),
          $1::text,
          $2::text,
          'Human feedback: ' || $3::text,
          'refined_analysis',
          'active',
          $4::integer
        )
        ON CONFLICT (id) DO NOTHING
        RETURNING id, session_id, original_content, edited_content, requirement_type, version, created_at
      ),
      session_update AS (
        UPDATE sessions
        SET status = 'refining_analysis', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        r.id, r.session_id, r.original_content, r.edited_content, r.requirement_type, r.version, r.created_at,
        s.status as session_status, s.updated_at as session_updated_at
      FROM req_insert r, session_update s;

  # HITL Enhance Analysis Workflow
  hitl-enhance-analysis-workflow:
    kind: postgres-sql
    source: cloudsql
    description: HITL Enhance workflow - store enhanced analysis with additional context
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: enhanced_analysis
        type: string
        description: Enhanced analysis with additional human context
      - name: enhancement_context
        type: string
        description: Additional context provided by human
    statement: |
      WITH req_insert AS (
        INSERT INTO requirements (id, session_id, original_content, edited_content, requirement_type, status)
        VALUES (
          $1::text || '_req_enhanced_' || substring(gen_random_uuid()::text, 1, 8),
          $1::text,
          $2::text,
          'Enhancement context: ' || $3::text,
          'enhanced_analysis',
          'active'
        )
        ON CONFLICT (id) DO NOTHING
        RETURNING id, session_id, original_content, edited_content, requirement_type, created_at
      ),
      session_update AS (
        UPDATE sessions
        SET status = 'enhancing_analysis', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        r.id, r.session_id, r.original_content, r.edited_content, r.requirement_type, r.created_at,
        s.status as session_status, s.updated_at as session_updated_at
      FROM req_insert r, session_update s;

  # HITL Process Edited Requirements
  hitl-process-edited-requirements:
    kind: postgres-sql
    source: cloudsql
    description: HITL Edited workflow - update existing requirement with human-edited content in edited_content field
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: edited_content
        type: string
        description: Human-edited requirements content
    statement: |
      WITH req_update AS (
        UPDATE requirements
        SET
          edited_content = $2::text,
          updated_at = NOW(),
          version = version + 1
        WHERE session_id = $1::text
          AND status = 'active'
          AND requirement_type IN ('original_analysis', 'functional', 'refined_analysis', 'enhanced_analysis')
        RETURNING id, session_id, original_content, edited_content, requirement_type, version, updated_at
      ),
      session_update AS (
        UPDATE sessions
        SET status = 'processing_edited_requirements', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        json_build_object(
          'database_result', json_build_object(
            'id', r.id,
            'session_id', r.session_id,
            'original_content', r.original_content,
            'edited_content', r.edited_content,
            'requirement_type', r.requirement_type,
            'version', r.version,
            'updated_at', r.updated_at,
            'session_status', s.status,
            'session_updated_at', s.updated_at
          ),
          'cache_data', json_build_object(
            'session_id', r.session_id,
            'requirements', json_build_array(
              json_build_object(
                'id', r.id,
                'original_content', r.original_content,
                'edited_content', r.edited_content,
                'type', r.requirement_type,
                'version', r.version,
                'status', 'active',
                'updated_at', r.updated_at
              )
            ),
            'status', s.status,
            'updated_at', s.updated_at
          ),
          'next_action', 'CALL cache-requirements-data with session_id and cache_data'
        ) as result
      FROM req_update r, session_update s;

  # Get Requirements for Session
  get-requirements-for-session:
    kind: postgres-sql
    source: cloudsql
    description: Get all requirements for a session to provide context for test case generation
    parameters:
      - name: session_id
        type: string
        description: Session UUID
    statement: |
      SELECT
        json_build_object(
          'session_id', $1::text,
          'requirements_found', COUNT(*),
          'requirements', json_agg(
            json_build_object(
              'id', id,
              'original_content', original_content,
              'edited_content', edited_content,
              'requirement_type', requirement_type,
              'priority', priority,
              'status', status,
              'version', version,
              'created_at', created_at,
              'updated_at', updated_at
            )
          )
        ) as result
      FROM requirements
      WHERE session_id = $1::text AND status = 'active'
      GROUP BY session_id;

  # HITL Approve and Generate Tests (Enhanced)
  hitl-approve-and-generate-tests:
    kind: postgres-sql
    source: cloudsql
    description: HITL Approved workflow - update session to generating_test_cases status and return requirements context
    parameters:
      - name: session_id
        type: string
        description: Session UUID
    statement: |
      WITH requirements_check AS (
        SELECT
          COUNT(*) as req_count,
          string_agg(
            CASE
              WHEN edited_content IS NOT NULL THEN edited_content
              ELSE original_content
            END,
            E'\n\n--- Next Requirement ---\n\n'
          ) as combined_requirements
        FROM requirements
        WHERE session_id = $1::text AND status = 'active'
      ),
      session_update AS (
        UPDATE sessions
        SET status = CASE
          WHEN (SELECT req_count FROM requirements_check) > 0 THEN 'generating_test_cases'
          ELSE 'missing_requirements'
        END, updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      )
      SELECT
        json_build_object(
          'session_id', $1::text,
          'session_status', s.status,
          'session_updated_at', s.updated_at,
          'requirements_count', r.req_count,
          'requirements_available', r.req_count > 0,
          'combined_requirements', CASE
            WHEN r.req_count > 0 THEN r.combined_requirements
            ELSE 'No requirements found for this session. Please analyze requirements first.'
          END,
          'message', CASE
            WHEN r.req_count > 0 THEN 'Session approved for test case generation with ' || r.req_count || ' requirements'
            ELSE 'Cannot generate test cases - no requirements found for session'
          END
        ) as result
      FROM session_update s, requirements_check r;

  # Parse and Store Test Cases - Primary tool for structured test case storage
  hitl-reject-workflow:
    kind: postgres-sql
    source: cloudsql
    description: HITL Rejected workflow - update session to workflow_rejected status
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: rejection_reason
        type: string
        description: Human rejection reason
    statement: |
      WITH session_update AS (
        UPDATE sessions
        SET status = 'workflow_rejected', updated_at = NOW()
        WHERE session_id = $1::text
        RETURNING session_id, status, updated_at
      ),
      rejection_log AS (
        INSERT INTO requirements (id, session_id, original_content, requirement_type, status)
        VALUES (
          $1::text || '_rejection_' || substring(gen_random_uuid()::text, 1, 8),
          $1::text,
          'Workflow rejected. Reason: ' || COALESCE($2::text, 'No reason provided'),
          'rejection_log',
          'rejected'
        )
        RETURNING id
      )
      SELECT
        s.session_id, s.status, s.updated_at,
        r.id as rejection_log_id
      FROM session_update s, rejection_log r;

  # SIMPLIFIED: Parse and Store Test Cases
  parse-and-store-test-cases:
    kind: postgres-sql
    source: cloudsql
    description: Parse structured test_cases JSON (handles both JSON and string-wrapped JSON) and insert into test_cases table
    parameters:
      - name: session_id
        type: string
        description: Session UUID
      - name: structured_test_cases
        type: string
        description: "JSON string or quoted JSON containing test_suite.test_cases array"
      - name: test_types_requested
        type: string
        description: "Optional filter for test types (functional, security, etc)"

    statement: |
      WITH parsed_json AS (
        SELECT
          CASE
            WHEN $2::text ~ '^".*"$' THEN
              (SUBSTRING($2::text, 2, LENGTH($2::text) - 2)::jsonb)
            WHEN $2::text ~ '^\{' THEN
              ($2::jsonb)
            ELSE
              ('{"test_suite":{"test_cases":[]}}'::jsonb)
          END ->'test_suite'->'test_cases' AS test_cases_array
      ),
      unpacked_tests AS (
        SELECT
          jsonb_array_elements(test_cases_array) AS test_case
        FROM parsed_json
      ),
      final_records AS (
        SELECT
          gen_random_uuid()::text AS id,
          $1::varchar AS session_id,
          COALESCE(test_case->>'test_id', 'Unknown')::varchar AS test_name,
          COALESCE(test_case->>'summary', '')::varchar AS test_description,
          COALESCE(test_case->'test_steps', '[]'::jsonb) AS test_steps,
          COALESCE(test_case->>'expected_result', '')::text AS expected_results,
          LOWER(COALESCE(test_case->>'type', 'functional'))::varchar AS test_type,
          LOWER(COALESCE(test_case->>'priority', 'medium'))::varchar AS priority,
          'active'::varchar AS status,
          COALESCE(test_case->'test_data', '{}'::jsonb) AS test_data,
          CASE
            WHEN jsonb_typeof(test_case->'preconditions') = 'array' THEN
              array_to_string(ARRAY(SELECT jsonb_array_elements_text(test_case->'preconditions')), '; ')
            ELSE
              COALESCE(test_case->>'preconditions', '')
          END::text AS preconditions,
          ''::text AS postconditions,
          30 AS estimated_duration,
          true AS automation_feasible,
          '[]'::jsonb AS tags,
          COALESCE(test_case->>'summary', '')::text AS summary,
          COALESCE(test_case->>'requirement_traceability', '')::text AS requirement_traceability
        FROM unpacked_tests
        WHERE
          CASE
            WHEN $3::text IS NULL OR $3::text = '' THEN true
            ELSE LOWER(COALESCE(test_case->>'type', 'functional')) = ANY(STRING_TO_ARRAY(LOWER($3::text), ','))
          END
      ),
      inserted_rows AS (
        INSERT INTO test_cases (
          id,
          session_id,
          test_name,
          test_description,
          test_steps,
          expected_results,
          test_type,
          priority,
          status,
          test_data,
          preconditions,
          postconditions,
          estimated_duration,
          automation_feasible,
          tags,
          summary,
          requirement_traceability
        )
        SELECT
          id,
          session_id,
          test_name,
          test_description,
          test_steps,
          expected_results,
          test_type,
          priority,
          status,
          test_data,
          preconditions,
          postconditions,
          estimated_duration,
          automation_feasible,
          tags,
          summary,
          requirement_traceability
        FROM final_records
        RETURNING id, test_name, test_type, priority, summary
      )
      SELECT
        json_build_object(
          'status', 'success',
          'session_id', $1,
          'test_cases_inserted', (SELECT COUNT(*) FROM inserted_rows),
          'test_cases', (
            SELECT json_agg(
              json_build_object(
                'id', id,
                'test_name', test_name,
                'test_type', test_type,
                'priority', priority,
                'summary', summary
              )
            )
            FROM inserted_rows
          )
        )::text AS result;

  # Redis Cache Management Tools (DISABLED - Redis connection issues)
  cache-requirements-data:
    kind: redis
    source: memorystore-redis
    description: Cache analyzed requirements data after storage/update for fast retrieval
    commands:
      - [SET, "requirements_analyzed:$session_id", "$requirements_data"]
    parameters:
      - name: session_id
        type: string
        description: Session UUID for cache key
      - name: requirements_data
        type: string
        description: JSON data of requirements to cache

  cache-test-cases-data:
    kind: redis
    source: memorystore-redis
    description: Cache generated test cases data after storage/update for fast retrieval
    commands:
      - [SET, "test_cases_generated:$session_id", "$test_cases_data"]
    parameters:
      - name: session_id
        type: string
        description: Session UUID for cache key
      - name: test_cases_data
        type: string
        description: JSON data of test cases to cache

  get-cached-requirements:
    kind: redis
    source: memorystore-redis
    description: Retrieve cached requirements data
    commands:
      - [GET, "requirements_analyzed:$session_id"]
    parameters:
      - name: session_id
        type: string
        description: Session UUID for cache key

  get-cached-test-cases:
    kind: redis
    source: memorystore-redis
    description: Retrieve cached test cases data
    commands:
      - [GET, "test_cases_generated:$session_id"]
    parameters:
      - name: session_id
        type: string
        description: Session UUID for cache key
